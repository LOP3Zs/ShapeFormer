import cv2
import numpy as np
import PIL.Image as Image
from typing import List, Dict, Any
from pycocotools import mask as maskUtils
import os
import json

def segm_to_mask(segmentation: List[List[float]], height: int, width: int) -> np.ndarray:
    """Chuyá»ƒn Ä‘á»•i segmentation polygon thÃ nh binary mask"""
    if isinstance(segmentation, list):
        rles = maskUtils.frPyObjects(segmentation, height, width)
        rle = maskUtils.merge(rles)
    else:
        rle = segmentation
    return maskUtils.decode(rle)

def mask_to_polygon(mask):
    """Chuyá»ƒn Ä‘á»•i binary mask thÃ nh polygon"""
    mask = (mask > 0).astype(np.uint8)
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    polygons = []
    for contour in contours:
        if len(contour) >= 3:
            contour = contour.reshape(-1, 2)
            polygon = contour.flatten().tolist()
            polygons.append(polygon)
    if len(polygons) == 0:
        return []
    return max(polygons, key=len)  # Tráº£ vá» contour lá»›n nháº¥t

def mask_to_bbox(mask):
    """TÃ­nh bbox tá»« mask"""
    coords = np.where(mask > 0)
    if len(coords[0]) == 0:
        return [0, 0, 0, 0]
    
    y_min, y_max = coords[0].min(), coords[0].max()
    x_min, x_max = coords[1].min(), coords[1].max()
    
    return [int(x_min), int(y_min), int(x_max - x_min), int(y_max - y_min)]

def create_class_object_matrix(image_id: str, coco_json: str) -> np.ndarray:
    """Táº¡o ma tráº­n 3D vá»›i class IDs tá»« COCO annotations"""
    with open(coco_json, 'r') as f:
        data = json.load(f)
    
    # TÃ¬m image info
    target_image_info = None
    for img in data['images']:
        img_basename = os.path.splitext(img['file_name'])[0]
        if img_basename == image_id:
            target_image_info = img
            break
    
    if not target_image_info:
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y áº£nh: {image_id}")
        return None
    
    img_width = target_image_info['width']
    img_height = target_image_info['height']
    
    # Láº¥y táº¥t cáº£ annotations cá»§a áº£nh nÃ y
    image_annotations = [ann for ann in data['annotations'] 
                        if ann['image_id'] == target_image_info['id']]
    
    if not image_annotations:
        print(f"âŒ KhÃ´ng cÃ³ annotations cho áº£nh: {image_id}")
        return None, None
    
    num_objects = len(image_annotations)
    print(f"âœ… áº¢nh {image_id}: {img_width}x{img_height}, {num_objects} objects")
    
    # Táº¡o ma tráº­n 3D: (height, width, num_objects)
    object_matrix = np.zeros((img_height, img_width, num_objects), dtype=np.uint8)
    
    # Xá»­ lÃ½ tá»«ng annotation
    for idx, ann in enumerate(image_annotations):
        segmentation = ann['segmentation']
        mask = segm_to_mask(segmentation, img_height, img_width)
        class_id = ann['category_id']
        object_matrix[:, :, idx] = np.where(mask, class_id, 0).astype(np.uint8)
    
    return object_matrix, image_annotations

def getDepth(instance_mask, filedepth):
    """TÃ­nh depth trung bÃ¬nh cá»§a object"""
    coords = (instance_mask != 0).astype(np.uint8)
    if not os.path.exists(filedepth):
        return 0
    depth = np.array(Image.open(filedepth))
    depth = np.resize(depth, (512, 512))
    vals = depth[coords == 1]
    mean_depth = np.mean(vals) if vals.size > 0 else 0
    return mean_depth

def arrange_occlusion(matrices, filedepth):
    """Sáº¯p xáº¿p objects theo depth"""
    H, W, N = matrices.shape
    depths = []
    class_ids = []

    for i in range(N):
        instance_mask = matrices[:, :, i]
        uniq_vals = np.unique(instance_mask)
        uniq_vals = uniq_vals[uniq_vals != 0]
        
        if len(uniq_vals) > 0:
            cid = int(uniq_vals[0])
        else:
            cid = -1

        if cid == 1:  # buffer luÃ´n dÆ°á»›i cÃ¹ng
            d = float("inf")
        else:
            d = getDepth(instance_mask, filedepth)

        depths.append((i, d))
        class_ids.append(cid)

    # Sáº¯p xáº¿p theo depth tÄƒng dáº§n (gáº§n nháº¥t trÆ°á»›c)
    depths_sorted = sorted(depths, key=lambda x: x[1])

    # Táº¡o máº£ng má»›i Ä‘Ã£ sáº¯p xáº¿p
    sorted_matrices = np.zeros_like(matrices)
    sorted_class_ids = []

    for new_idx, (old_idx, _) in enumerate(depths_sorted):
        sorted_matrices[:, :, new_idx] = matrices[:, :, old_idx]
        sorted_class_ids.append(class_ids[old_idx])

    return sorted_matrices

def getVisibleObjects(matrix):
    """Táº¡o visible masks báº±ng cÃ¡ch loáº¡i bá» pháº§n bá»‹ che"""
    H, W, N = matrix.shape
    visible_objects = np.zeros((H, W, N), dtype=np.uint8)

    for i in range(N):
        instance_mask = matrix[:, :, i]
        class_ids = np.unique(instance_mask)
        class_ids = class_ids[class_ids != 0]

        if len(class_ids) == 0:
            continue
        cid = int(class_ids[0])

        # Chuáº©n hÃ³a mask hiá»‡n táº¡i
        current_mask = (instance_mask > 0).astype(np.uint8)

        # Loáº¡i bá» pháº§n bá»‹ che bá»Ÿi cÃ¡c mask trÆ°á»›c Ä‘Ã³ (gáº§n hÆ¡n)
        for j in range(i):
            prev_mask = (matrix[:, :, j] > 0).astype(np.uint8)
            current_mask = current_mask * (1 - prev_mask)

        # GÃ¡n class_id cho visible part
        visible_objects[:, :, i] = current_mask * cid

    return visible_objects

def find_occluders(visible_mask, amodal_mask, sorted_matrices, current_idx):
    """TÃ¬m cÃ¡c objects che khuáº¥t object hiá»‡n táº¡i"""
    occluders = []
    
    # Pháº§n bá»‹ che = amodal - visible
    occluded_part = np.logical_and(amodal_mask > 0, visible_mask == 0)
    
    if not np.any(occluded_part):
        return occluders
    
    # Kiá»ƒm tra cÃ¡c objects trÆ°á»›c (gáº§n hÆ¡n) cÃ³ che khÃ´ng
    for j in range(current_idx):
        occluder_mask = (sorted_matrices[:, :, j] > 0).astype(np.uint8)
        
        # Náº¿u cÃ³ overlap vá»›i pháº§n bá»‹ che
        if np.any(np.logical_and(occluded_part, occluder_mask)):
            class_ids = np.unique(sorted_matrices[:, :, j])
            class_ids = class_ids[class_ids != 0]
            if len(class_ids) > 0:
                occluders.append(int(class_ids[0]))
    
    return occluders

def create_cocoa_format(coco_json: str, output_json: str, depth_dir: str):
    """
    Táº¡o file JSON theo format COCOA vá»›i visible vÃ  amodal masks
    """
    with open(coco_json, 'r') as f:
        data = json.load(f)
    
    categories = data['categories']
    images = []
    annotations = []
    annotation_id = 1
    
    for img in data['images']:
        img_id = img['id']
        img_filename = img['file_name']
        height = img['height']
        width = img['width']
        
        # ThÃªm depth file info
        depth_path = img_filename[:6]
        depth_file = f"{depth_path}_depth.png"
        
        new_image = {
            "id": img_id,
            "file_name": img_filename,
            "width": width,
            "height": height,
            "depth_file": depth_file
        }
        images.append(new_image)
        
        # Xá»­ lÃ½ annotations cho áº£nh nÃ y
        file_name = os.path.splitext(img_filename)[0]
        amodal_matrix, original_annotations = create_class_object_matrix(file_name, coco_json)
        
        if amodal_matrix is None:
            continue
            
        # Sáº¯p xáº¿p theo depth
        depth_file_path = os.path.join(depth_dir, depth_file)
        sorted_matrix = arrange_occlusion(amodal_matrix, depth_file_path)
        
        # Táº¡o visible masks
        visible_matrix = getVisibleObjects(sorted_matrix)
        
        # Táº¡o annotations cho tá»«ng object
        H, W, N = amodal_matrix.shape
        
        for i in range(N):
            amodal_mask = sorted_matrix[:, :, i]
            visible_mask = visible_matrix[:, :, i]
            
            # Láº¥y class ID
            class_ids = np.unique(amodal_mask)
            class_ids = class_ids[class_ids != 0]
            
            if len(class_ids) == 0:
                continue
                
            class_id = int(class_ids[0])
            
            # Táº¡o polygons
            amodal_polygon = mask_to_polygon(amodal_mask)
            visible_polygon = mask_to_polygon(visible_mask)
            
            if len(amodal_polygon) == 0:
                continue
            
            # TÃ­nh bboxes
            amodal_bbox = mask_to_bbox(amodal_mask)
            visible_bbox = mask_to_bbox(visible_mask) if len(visible_polygon) > 0 else [0, 0, 0, 0]
            
            # TÃ¬m occluders
            occluders = find_occluders(visible_mask, amodal_mask, sorted_matrix, i)
            
            annotation = {
                "id": annotation_id,
                "image_id": img_id,
                "category_id": class_id,
                "visible_segm": [visible_polygon] if len(visible_polygon) > 0 else [],
                "visible_bbox": visible_bbox,
                "amodal_segm": [amodal_polygon],
                "amodal_bbox": amodal_bbox,
                "iscrowd": 0,
                "occluders": occluders,
                "area": int(np.sum(amodal_mask > 0)),
                "visible_area": int(np.sum(visible_mask > 0))
            }
            
            annotations.append(annotation)
            annotation_id += 1
    
    # In thÃ´ng tin classes
    print("ğŸ·ï¸  Classes Ä‘Æ°á»£c sá»­ dá»¥ng:")
    used_classes = set(ann['category_id'] for ann in annotations)
    for cat in categories:
        if cat['id'] in used_classes:
            print(f"   {cat['id']}: {cat['name']}")
    
    # Táº¡o dá»¯ liá»‡u má»›i theo format COCOA
    cocoa_data = {
        "images": images,
        "annotations": annotations,
        "categories": categories
    }
    
    # Ghi file
    with open(output_json, 'w') as f:
        json.dump(cocoa_data, f, indent=2)
    
    print(f"âœ… ÄÃ£ táº¡o file COCOA format: {output_json}")
    print(f"ğŸ“Š Tá»•ng sá»‘ áº£nh: {len(images)}")
    print(f"ğŸ“Š Tá»•ng sá»‘ annotations: {len(annotations)}")

if __name__ == "__main__":
    coco_json = "train/_annotations.coco.json"
    output_json = "train/cocoa_format_annotations.json"
    depth_dir = "train/depth"
    
    create_cocoa_format(coco_json, output_json, depth_dir)